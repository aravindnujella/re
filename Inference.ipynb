{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_lib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*output shape of zoom.*')\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(model_lib)\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 1\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    # not going to use these\n",
    "    N_DISTORTIONS = 0\n",
    "    MAX_DISTORTION = 0.3\n",
    "    MIN_DISTORTION = -0.1\n",
    "    \n",
    "    VALIDATION_STEPS = 20\n",
    "    # including gt\n",
    "    NUM_CLASSES = 81\n",
    "    # only flips\n",
    "    IMAGE_AUGMENT = True\n",
    "\n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9],dtype=np.float32)\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    CLASS_NAMES = [\n",
    "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    LEARNING_RATE = 0.05\n",
    "    LEARNING_MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "    MASK_SHAPE = (64,64)\n",
    "    GRID_WIDTH = 16\n",
    "    GRID_HEIGHT = 16\n",
    "    CLUE_SHAPE = (20,20)\n",
    "    GRID_SHAPE = (GRID_WIDTH, GRID_HEIGHT)\n",
    "    GRID_RESOLUTION = (1, 1)\n",
    "    IS_PADDED = True\n",
    "    MASK_THRESOLD = 0.7\n",
    "    def __init__(self):\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT,3)\n",
    "        self.MAX_BATCH_SIZE = self.BATCH_SIZE*32\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7584514617919922\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/media/data/nishanth/aravind/\"\n",
    "config = ProposalConfig()\n",
    "model_dir = \"./models/\"\n",
    "train_dataset,val_dataset = None,None\n",
    "train_pickle = root_dir+\"val_cid.pickle\"\n",
    "val_pickle = root_dir+\"val_cid.pickle\"\n",
    "class ClassInstancesDataset():\n",
    "    def __init__(self):\n",
    "        self.class_wise_instance_info = [[] for i in range(81)]\n",
    "        self.instance_info = []\n",
    "import time\n",
    "start = time.time()\n",
    "with open(train_pickle,\"rb\") as train_ann:\n",
    "    train_cid = pickle.load(train_ann)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "#     train_dataset = model_lib.CocoDataset(train_cid,config)\n",
    "with open(val_pickle,\"rb\") as val_ann:\n",
    "    val_cid = pickle.load(val_ann)\n",
    "#     val_dataset = model_lib.CocoDataset(val_cid,config)\n",
    "train_loader = model_lib.get_loader(train_cid,config,\"cw_ins\")\n",
    "val_loader = model_lib.get_loader(val_cid,config,\"ins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1920, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.5745, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.2908, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       3.5708, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       3.1190, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       3.1010, device='cuda:0') tensor(75, device='cuda:0') clock\n",
      "tensor(1.00000e-02 *\n",
      "       3.0926, device='cuda:0') tensor(16, device='cuda:0') cat\n",
      "tensor(1.00000e-02 *\n",
      "       2.9018, device='cuda:0') tensor(76, device='cuda:0') vase\n",
      "tensor(1.00000e-02 *\n",
      "       2.8602, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       2.8255, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "gt_class: clock\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       7.1131, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       6.7114, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.3948, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.4654, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       4.6567, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       4.2984, device='cuda:0') tensor(59, device='cuda:0') potted plant\n",
      "tensor(1.00000e-02 *\n",
      "       4.1593, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       4.0610, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       3.7287, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       3.3638, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "gt_class: BG\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1033, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       8.7836, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       4.9519, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.7467, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       4.6030, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       4.2302, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       4.1607, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       4.0317, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       3.8500, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       3.7844, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "gt_class: oven\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1685, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       8.5684, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.7971, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       5.5331, device='cuda:0') tensor(18, device='cuda:0') horse\n",
      "tensor(1.00000e-02 *\n",
      "       3.0469, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       2.9894, device='cuda:0') tensor(20, device='cuda:0') cow\n",
      "tensor(1.00000e-02 *\n",
      "       2.9626, device='cuda:0') tensor(19, device='cuda:0') sheep\n",
      "tensor(1.00000e-02 *\n",
      "       2.6720, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.5300, device='cuda:0') tensor(59, device='cuda:0') potted plant\n",
      "tensor(1.00000e-02 *\n",
      "       2.3171, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "gt_class: BG\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1286, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       9.1061, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       8.4472, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       6.5538, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       4.1604, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.1378, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       2.9123, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "tensor(1.00000e-02 *\n",
      "       2.4772, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.4124, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       2.3267, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "gt_class: person\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1748, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1022, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.6917, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       5.5151, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       5.4765, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       5.1990, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       4.4379, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       4.2002, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.7345, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       2.8328, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "gt_class: car\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       9.4034, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       8.7110, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.6523, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       5.5932, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       4.9948, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       4.8035, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       4.5047, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       4.4167, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "tensor(1.00000e-02 *\n",
      "       3.9153, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       3.6904, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "gt_class: cake\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1486, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1059, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       8.1278, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.9271, device='cuda:0') tensor(62, device='cuda:0') toilet\n",
      "tensor(1.00000e-02 *\n",
      "       4.0604, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       3.7500, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.6620, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.9613, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       2.9482, device='cuda:0') tensor(78, device='cuda:0') teddy bear\n",
      "tensor(1.00000e-02 *\n",
      "       2.5470, device='cuda:0') tensor(16, device='cuda:0') cat\n",
      "gt_class: person\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1158, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1063, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       7.3331, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       4.3359, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.1425, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.6604, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.2573, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       3.2027, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       3.1914, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       3.0416, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "gt_class: person\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1376, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1046, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       9.3187, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       6.8011, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.2684, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       4.1592, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       3.8226, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.7063, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       2.6089, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       2.5939, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "gt_class: person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       9.2628, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       8.6620, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       6.3187, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       5.5934, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       4.5691, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       3.6755, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.3167, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       3.1337, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       2.8891, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       2.8642, device='cuda:0') tensor(16, device='cuda:0') cat\n",
      "gt_class: tv\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1552, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       8.1415, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       6.3841, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       4.1039, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       3.9370, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       3.6658, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       3.6063, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       3.4704, device='cuda:0') tensor(16, device='cuda:0') cat\n",
      "tensor(1.00000e-02 *\n",
      "       3.4633, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "tensor(1.00000e-02 *\n",
      "       3.4001, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "gt_class: truck\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       7.7584, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       6.7573, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "tensor(1.00000e-02 *\n",
      "       6.6643, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.0153, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       4.9898, device='cuda:0') tensor(40, device='cuda:0') bottle\n",
      "tensor(1.00000e-02 *\n",
      "       4.3022, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       3.3367, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.3120, device='cuda:0') tensor(15, device='cuda:0') bird\n",
      "tensor(1.00000e-02 *\n",
      "       2.9930, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       2.7464, device='cuda:0') tensor(76, device='cuda:0') vase\n",
      "gt_class: bowl\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1317, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1152, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       7.5537, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       6.1574, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       5.1774, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       4.5225, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       4.4960, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.0627, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       3.0087, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       2.2140, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "gt_class: car\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1178, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.9122, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.5794, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       5.0018, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       4.8185, device='cuda:0') tensor(59, device='cuda:0') potted plant\n",
      "tensor(1.00000e-02 *\n",
      "       4.5903, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       3.7731, device='cuda:0') tensor(76, device='cuda:0') vase\n",
      "tensor(1.00000e-02 *\n",
      "       3.5878, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       3.2224, device='cuda:0') tensor(40, device='cuda:0') bottle\n",
      "tensor(1.00000e-02 *\n",
      "       3.0181, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "gt_class: handbag\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1050, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.9280, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       6.1868, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       5.2137, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "tensor(1.00000e-02 *\n",
      "       5.1033, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       5.0958, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.2420, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       4.1939, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.5648, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       3.3975, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "gt_class: keyboard\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       8.8051, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       8.2323, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       5.7220, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       5.5262, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.3776, device='cuda:0') tensor(76, device='cuda:0') vase\n",
      "tensor(1.00000e-02 *\n",
      "       4.5358, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       4.2947, device='cuda:0') tensor(59, device='cuda:0') potted plant\n",
      "tensor(1.00000e-02 *\n",
      "       3.8078, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       3.5477, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       3.3577, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "gt_class: tennis racket\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1401, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       9.2398, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       8.1026, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       6.2172, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       5.7011, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       5.6472, device='cuda:0') tensor(58, device='cuda:0') couch\n",
      "tensor(1.00000e-02 *\n",
      "       3.3997, device='cuda:0') tensor(18, device='cuda:0') horse\n",
      "tensor(1.00000e-02 *\n",
      "       3.1540, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       3.0924, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.0414, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "gt_class: surfboard\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(0.1145, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.8691, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       4.9103, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       4.4435, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       4.2100, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.8669, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.6278, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.4919, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       3.4645, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       3.2102, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "gt_class: person\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       7.7289, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.1362, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       6.7216, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.8023, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       4.7131, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       4.3973, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       4.1040, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.8435, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-02 *\n",
      "       3.4792, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.3821, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "gt_class: cup\n",
      "\n",
      "torch.Size([10]) torch.Size([10])\n",
      "tensor(1.00000e-02 *\n",
      "       8.8953, device='cuda:0') tensor(29, device='cuda:0') suitcase\n",
      "tensor(1.00000e-02 *\n",
      "       5.9680, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "tensor(1.00000e-02 *\n",
      "       5.7436, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.5704, device='cuda:0') tensor(25, device='cuda:0') backpack\n",
      "tensor(1.00000e-02 *\n",
      "       5.5191, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       5.1689, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.6530, device='cuda:0') tensor(27, device='cuda:0') handbag\n",
      "tensor(1.00000e-02 *\n",
      "       4.1553, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       3.8703, device='cuda:0') tensor(56, device='cuda:0') cake\n",
      "tensor(1.00000e-02 *\n",
      "       3.2970, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "gt_class: umbrella\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-108:\n",
      "Process Process-106:\n",
      "Process Process-100:\n",
      "Process Process-111:\n",
      "Process Process-112:\n",
      "Process Process-104:\n",
      "Process Process-107:\n",
      "Traceback (most recent call last):\n",
      "Process Process-97:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-102:\n",
      "Process Process-105:\n",
      "Process Process-99:\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-103:\n",
      "Traceback (most recent call last):\n",
      "Process Process-109:\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "Process Process-98:\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "Traceback (most recent call last):\n",
      "Process Process-101:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-110:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 52, in _worker_loop\n",
      "    r = index_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    728\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 729\u001b[0;31m                 \u001b[0mident\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdin_socket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    730\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/jupyter_client/session.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, socket, mode, content, copy)\u001b[0m\n\u001b[1;32m    802\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 803\u001b[0;31m             \u001b[0mmsg_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    804\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mzmq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZMQError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36mrecv_multipart\u001b[0;34m(self, flags, copy, track)\u001b[0m\n\u001b[1;32m    465\u001b[0m         \"\"\"\n\u001b[0;32m--> 466\u001b[0;31m         \u001b[0mparts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    467\u001b[0m         \u001b[0;31m# have first part already, only loop while more to receive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.recv\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._recv_copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/zmq/backend/cython/checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-91b55d099b8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"gt_class:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCLASS_NAMES\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_class_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;31m#         print(config.CLASS_NAMES[int(indices[0])])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 704\u001b[0;31m             \u001b[0mpassword\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    705\u001b[0m         )\n\u001b[1;32m    706\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    732\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "net = model_lib.SimpleHGModel()\n",
    "net.load_state_dict(torch.load(model_dir+\"model_3_16000.pt\"))\n",
    "net = net.cuda()\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(val_loader):\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_class_ids = data\n",
    "        a,b,c= batch_images.numpy(), batch_impulses.numpy(),batch_gt_responses.numpy()\n",
    "        a = np.moveaxis(a,1,-1)\n",
    "        b = np.moveaxis(b,1,-1)\n",
    "        c = np.moveaxis(c,1,-1)\n",
    "        Image.fromarray((a[0]*128 + config.MEAN_PIXEL).astype(np.uint8),\"RGB\").show()\n",
    "        Image.fromarray((b[0][:,:,0]*128).astype(np.uint8),\"L\").show()\n",
    "        Image.fromarray((c[0][:,:,0]*128).astype(np.uint8),\"L\").show()\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_class_ids = batch_images.cuda(),batch_impulses.cuda(),batch_gt_responses.cuda(),batch_class_ids.cuda()\n",
    "        pred_class = net([batch_images,batch_impulses])\n",
    "#         print(pred_class)\n",
    "        pred_class = F.softmax(pred_class,dim=-1).squeeze()\n",
    "        maxs, indices = torch.topk(pred_class,5,-1)\n",
    "        print(maxs.shape,indices.shape)\n",
    "        for i in range(5):\n",
    "            print(maxs[i],indices[i],config.CLASS_NAMES[int(indices[i])])\n",
    "#         print(batch_class_ids)\n",
    "#         print(indices)\n",
    "        print(\"gt_class:\",config.CLASS_NAMES[int(batch_class_ids[0])])\n",
    "#         print(config.CLASS_NAMES[int(indices[0])])\n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:0\n",
      "sample:1\n",
      "sample:2\n",
      "sample:3\n",
      "sample:4\n",
      "sample:5\n",
      "sample:6\n",
      "sample:7\n",
      "sample:8\n",
      "sample:9\n",
      "sample:10\n",
      "sample:11\n",
      "sample:12\n",
      "sample:13\n",
      "sample:14\n",
      "sample:15\n",
      "sample:16\n",
      "sample:17\n",
      "sample:18\n",
      "sample:19\n",
      "sample:20\n",
      "sample:21\n",
      "sample:22\n",
      "sample:23\n",
      "sample:24\n",
      "sample:25\n",
      "sample:26\n",
      "sample:27\n",
      "sample:28\n",
      "sample:29\n",
      "sample:30\n",
      "sample:31\n",
      "sample:32\n",
      "sample:33\n",
      "sample:34\n",
      "sample:35\n",
      "sample:36\n",
      "sample:37\n",
      "sample:38\n",
      "sample:39\n",
      "sample:40\n",
      "sample:41\n",
      "sample:42\n",
      "sample:43\n",
      "sample:44\n",
      "sample:45\n",
      "sample:46\n",
      "sample:47\n",
      "sample:48\n",
      "sample:49\n",
      "sample:50\n",
      "sample:51\n",
      "sample:52\n",
      "sample:53\n",
      "sample:54\n",
      "sample:55\n",
      "sample:56\n",
      "sample:57\n",
      "sample:58\n",
      "sample:59\n",
      "sample:60\n",
      "sample:61\n",
      "sample:62\n",
      "sample:63\n",
      "sample:64\n",
      "sample:65\n",
      "sample:66\n",
      "sample:67\n",
      "sample:68\n",
      "sample:69\n",
      "sample:70\n",
      "sample:71\n",
      "sample:72\n",
      "sample:73\n",
      "sample:74\n",
      "sample:75\n",
      "sample:76\n",
      "sample:77\n",
      "sample:78\n",
      "sample:79\n",
      "sample:80\n",
      "sample:81\n",
      "sample:82\n",
      "sample:83\n",
      "sample:84\n",
      "sample:85\n",
      "sample:86\n",
      "sample:87\n",
      "sample:88\n",
      "sample:89\n",
      "sample:90\n",
      "sample:91\n",
      "sample:92\n",
      "sample:93\n",
      "sample:94\n",
      "sample:95\n",
      "sample:96\n",
      "sample:97\n",
      "sample:98\n",
      "sample:99\n",
      "sample:100\n",
      "sample:101\n",
      "sample:102\n",
      "sample:103\n",
      "sample:104\n",
      "sample:105\n",
      "sample:106\n",
      "sample:107\n",
      "sample:108\n",
      "sample:109\n",
      "sample:110\n",
      "sample:111\n",
      "sample:112\n",
      "sample:113\n",
      "sample:114\n",
      "sample:115\n",
      "sample:116\n",
      "sample:117\n",
      "sample:118\n",
      "sample:119\n",
      "sample:120\n",
      "sample:121\n",
      "sample:122\n",
      "sample:123\n",
      "sample:124\n",
      "sample:125\n",
      "sample:126\n",
      "sample:127\n",
      "sample:128\n",
      "sample:129\n",
      "sample:130\n",
      "sample:131\n",
      "sample:132\n",
      "sample:133\n",
      "sample:134\n",
      "sample:135\n",
      "sample:136\n",
      "sample:137\n",
      "sample:138\n",
      "sample:139\n",
      "sample:140\n",
      "sample:141\n",
      "sample:142\n",
      "sample:143\n",
      "sample:144\n",
      "sample:145\n",
      "sample:146\n",
      "sample:147\n",
      "sample:148\n",
      "sample:149\n",
      "sample:150\n",
      "sample:151\n",
      "sample:152\n",
      "sample:153\n",
      "sample:154\n",
      "sample:155\n",
      "sample:156\n",
      "sample:157\n",
      "sample:158\n",
      "sample:159\n",
      "sample:160\n",
      "sample:161\n",
      "sample:162\n",
      "sample:163\n",
      "sample:164\n",
      "sample:165\n",
      "sample:166\n",
      "sample:167\n",
      "sample:168\n",
      "sample:169\n",
      "sample:170\n",
      "sample:171\n",
      "sample:172\n",
      "sample:173\n",
      "sample:174\n",
      "sample:175\n",
      "sample:176\n",
      "sample:177\n",
      "sample:178\n",
      "sample:179\n",
      "sample:180\n",
      "sample:181\n",
      "sample:182\n",
      "sample:183\n",
      "sample:184\n",
      "sample:185\n",
      "sample:186\n",
      "sample:187\n",
      "sample:188\n",
      "sample:189\n",
      "sample:190\n",
      "sample:191\n",
      "sample:192\n",
      "sample:193\n",
      "sample:194\n",
      "sample:195\n",
      "sample:196\n",
      "sample:197\n",
      "sample:198\n",
      "sample:199\n",
      "sample:200\n",
      "sample:201\n",
      "sample:202\n",
      "sample:203\n",
      "sample:204\n",
      "sample:205\n",
      "sample:206\n",
      "sample:207\n",
      "sample:208\n",
      "sample:209\n",
      "sample:210\n",
      "sample:211\n",
      "sample:212\n",
      "sample:213\n",
      "sample:214\n",
      "sample:215\n",
      "sample:216\n",
      "sample:217\n",
      "sample:218\n",
      "sample:219\n",
      "sample:220\n",
      "sample:221\n",
      "sample:222\n",
      "sample:223\n",
      "sample:224\n",
      "sample:225\n",
      "sample:226\n",
      "sample:227\n",
      "sample:228\n",
      "sample:229\n",
      "sample:230\n",
      "sample:231\n",
      "sample:232\n",
      "sample:233\n",
      "sample:234\n",
      "sample:235\n",
      "sample:236\n",
      "sample:237\n",
      "sample:238\n",
      "sample:239\n",
      "sample:240\n",
      "sample:241\n",
      "sample:242\n",
      "sample:243\n",
      "sample:244\n",
      "sample:245\n",
      "sample:246\n",
      "sample:247\n",
      "sample:248\n",
      "sample:249\n",
      "sample:250\n",
      "sample:251\n",
      "sample:252\n",
      "sample:253\n",
      "sample:254\n",
      "sample:255\n",
      "sample:256\n",
      "sample:257\n",
      "sample:258\n",
      "sample:259\n",
      "sample:260\n",
      "sample:261\n",
      "sample:262\n",
      "sample:263\n",
      "sample:264\n",
      "sample:265\n",
      "sample:266\n",
      "sample:267\n",
      "sample:268\n",
      "sample:269\n",
      "sample:270\n",
      "sample:271\n",
      "sample:272\n",
      "sample:273\n",
      "sample:274\n",
      "sample:275\n",
      "sample:276\n",
      "sample:277\n",
      "sample:278\n",
      "sample:279\n",
      "sample:280\n",
      "sample:281\n",
      "sample:282\n",
      "sample:283\n",
      "sample:284\n",
      "sample:285\n",
      "sample:286\n",
      "sample:287\n",
      "sample:288\n",
      "sample:289\n",
      "sample:290\n",
      "sample:291\n",
      "sample:292\n",
      "sample:293\n",
      "sample:294\n",
      "sample:295\n",
      "sample:296\n",
      "sample:297\n",
      "sample:298\n",
      "sample:299\n",
      "sample:300\n",
      "sample:301\n",
      "sample:302\n",
      "sample:303\n",
      "sample:304\n",
      "sample:305\n",
      "sample:306\n",
      "sample:307\n",
      "sample:308\n",
      "sample:309\n",
      "sample:310\n",
      "sample:311\n",
      "sample:312\n",
      "sample:313\n",
      "sample:314\n",
      "sample:315\n",
      "sample:316\n",
      "sample:317\n",
      "sample:318\n",
      "sample:319\n",
      "sample:320\n",
      "sample:321\n",
      "sample:322\n",
      "sample:323\n",
      "sample:324\n",
      "sample:325\n",
      "sample:326\n",
      "sample:327\n",
      "sample:328\n",
      "sample:329\n",
      "sample:330\n",
      "sample:331\n",
      "sample:332\n",
      "sample:333\n",
      "sample:334\n",
      "sample:335\n",
      "sample:336\n",
      "sample:337\n",
      "sample:338\n",
      "sample:339\n",
      "sample:340\n",
      "sample:341\n",
      "sample:342\n",
      "sample:343\n",
      "sample:344\n",
      "sample:345\n",
      "sample:346\n",
      "sample:347\n",
      "sample:348\n",
      "sample:349\n",
      "sample:350\n",
      "sample:351\n",
      "sample:352\n",
      "sample:353\n",
      "sample:354\n",
      "sample:355\n",
      "sample:356\n",
      "sample:357\n",
      "sample:358\n",
      "sample:359\n",
      "sample:360\n",
      "sample:361\n",
      "sample:362\n",
      "sample:363\n",
      "sample:364\n",
      "sample:365\n",
      "sample:366\n",
      "sample:367\n",
      "sample:368\n",
      "sample:369\n",
      "sample:370\n",
      "sample:371\n",
      "sample:372\n",
      "sample:373\n",
      "sample:374\n",
      "sample:375\n",
      "sample:376\n",
      "sample:377\n",
      "sample:378\n",
      "sample:379\n",
      "sample:380\n",
      "sample:381\n",
      "sample:382\n",
      "sample:383\n",
      "sample:384\n",
      "sample:385\n",
      "sample:386\n",
      "sample:387\n",
      "sample:388\n",
      "sample:389\n",
      "sample:390\n",
      "sample:391\n",
      "sample:392\n",
      "sample:393\n",
      "sample:394\n",
      "sample:395\n",
      "sample:396\n",
      "sample:397\n",
      "sample:398\n",
      "sample:399\n",
      "sample:400\n",
      "sample:401\n",
      "sample:402\n",
      "sample:403\n",
      "sample:404\n",
      "sample:405\n",
      "sample:406\n",
      "sample:407\n",
      "sample:408\n",
      "sample:409\n",
      "sample:410\n",
      "sample:411\n",
      "sample:412\n",
      "sample:413\n",
      "sample:414\n",
      "sample:415\n",
      "sample:416\n",
      "sample:417\n",
      "sample:418\n",
      "sample:419\n",
      "sample:420\n",
      "sample:421\n",
      "sample:422\n",
      "sample:423\n",
      "sample:424\n",
      "sample:425\n",
      "sample:426\n",
      "sample:427\n",
      "sample:428\n",
      "sample:429\n",
      "sample:430\n",
      "sample:431\n",
      "sample:432\n",
      "sample:433\n",
      "sample:434\n",
      "sample:435\n",
      "sample:436\n",
      "sample:437\n",
      "sample:438\n",
      "sample:439\n",
      "sample:440\n",
      "sample:441\n",
      "sample:442\n",
      "sample:443\n",
      "sample:444\n",
      "sample:445\n",
      "sample:446\n",
      "sample:447\n",
      "sample:448\n",
      "sample:449\n",
      "sample:450\n",
      "sample:451\n",
      "sample:452\n",
      "sample:453\n",
      "sample:454\n",
      "sample:455\n",
      "sample:456\n",
      "sample:457\n",
      "sample:458\n",
      "sample:459\n",
      "sample:460\n",
      "sample:461\n",
      "sample:462\n",
      "sample:463\n",
      "sample:464\n",
      "sample:465\n",
      "sample:466\n",
      "sample:467\n",
      "sample:468\n",
      "sample:469\n",
      "sample:470\n",
      "sample:471\n",
      "sample:472\n",
      "sample:473\n",
      "sample:474\n",
      "sample:475\n",
      "sample:476\n",
      "sample:477\n",
      "sample:478\n",
      "sample:479\n",
      "sample:480\n",
      "sample:481\n",
      "sample:482\n",
      "sample:483\n",
      "sample:484\n",
      "sample:485\n",
      "sample:486\n",
      "sample:487\n",
      "sample:488\n",
      "sample:489\n",
      "sample:490\n",
      "sample:491\n",
      "sample:492\n",
      "sample:493\n",
      "sample:494\n",
      "sample:495\n",
      "sample:496\n",
      "sample:497\n",
      "sample:498\n",
      "sample:499\n",
      "sample:500\n",
      "sample:501\n",
      "sample:502\n",
      "sample:503\n",
      "sample:504\n",
      "sample:505\n",
      "sample:506\n",
      "sample:507\n",
      "sample:508\n",
      "sample:509\n",
      "sample:510\n",
      "sample:511\n",
      "sample:512\n",
      "sample:513\n",
      "sample:514\n",
      "sample:515\n",
      "sample:516\n",
      "sample:517\n",
      "sample:518\n",
      "sample:519\n",
      "sample:520\n",
      "sample:521\n",
      "sample:522\n",
      "sample:523\n",
      "sample:524\n",
      "sample:525\n",
      "sample:526\n",
      "sample:527\n",
      "sample:528\n",
      "sample:529\n",
      "sample:530\n",
      "sample:531\n",
      "sample:532\n",
      "sample:533\n",
      "sample:534\n",
      "sample:535\n",
      "sample:536\n",
      "sample:537\n",
      "sample:538\n",
      "sample:539\n",
      "sample:540\n",
      "sample:541\n",
      "sample:542\n",
      "sample:543\n",
      "sample:544\n",
      "sample:545\n",
      "sample:546\n",
      "sample:547\n",
      "sample:548\n",
      "sample:549\n",
      "sample:550\n",
      "sample:551\n",
      "sample:552\n",
      "sample:553\n",
      "sample:554\n",
      "sample:555\n",
      "sample:556\n",
      "sample:557\n",
      "sample:558\n",
      "sample:559\n",
      "sample:560\n",
      "sample:561\n",
      "sample:562\n",
      "sample:563\n",
      "sample:564\n",
      "sample:565\n",
      "sample:566\n",
      "sample:567\n",
      "sample:568\n",
      "sample:569\n",
      "sample:570\n",
      "sample:571\n",
      "sample:572\n",
      "sample:573\n",
      "sample:574\n",
      "sample:575\n",
      "sample:576\n",
      "sample:577\n",
      "sample:578\n",
      "sample:579\n",
      "sample:580\n",
      "sample:581\n",
      "sample:582\n",
      "sample:583\n",
      "sample:584\n",
      "sample:585\n",
      "sample:586\n",
      "sample:587\n",
      "sample:588\n",
      "sample:589\n",
      "sample:590\n",
      "sample:591\n",
      "sample:592\n",
      "sample:593\n",
      "sample:594\n",
      "sample:595\n",
      "sample:596\n",
      "sample:597\n",
      "sample:598\n",
      "sample:599\n",
      "sample:600\n",
      "sample:601\n",
      "sample:602\n",
      "sample:603\n",
      "sample:604\n",
      "sample:605\n",
      "sample:606\n",
      "sample:607\n",
      "sample:608\n",
      "sample:609\n",
      "sample:610\n",
      "sample:611\n",
      "sample:612\n",
      "sample:613\n",
      "sample:614\n",
      "sample:615\n",
      "sample:616\n",
      "sample:617\n",
      "sample:618\n",
      "sample:619\n",
      "sample:620\n",
      "sample:621\n",
      "sample:622\n",
      "sample:623\n",
      "sample:624\n",
      "sample:625\n",
      "sample:626\n",
      "sample:627\n",
      "sample:628\n",
      "sample:629\n",
      "sample:630\n",
      "sample:631\n",
      "sample:632\n",
      "sample:633\n",
      "sample:634\n",
      "sample:635\n",
      "sample:636\n",
      "sample:637\n",
      "sample:638\n",
      "sample:639\n",
      "sample:640\n",
      "sample:641\n",
      "sample:642\n",
      "sample:643\n",
      "sample:644\n",
      "sample:645\n",
      "sample:646\n",
      "sample:647\n",
      "sample:648\n",
      "sample:649\n",
      "sample:650\n",
      "sample:651\n",
      "sample:652\n",
      "sample:653\n",
      "sample:654\n",
      "sample:655\n",
      "sample:656\n",
      "sample:657\n",
      "sample:658\n",
      "sample:659\n",
      "sample:660\n",
      "sample:661\n",
      "sample:662\n",
      "sample:663\n",
      "sample:664\n",
      "sample:665\n",
      "sample:666\n",
      "sample:667\n",
      "sample:668\n",
      "sample:669\n",
      "sample:670\n",
      "sample:671\n",
      "sample:672\n",
      "sample:673\n",
      "sample:674\n",
      "sample:675\n",
      "sample:676\n",
      "sample:677\n",
      "sample:678\n",
      "sample:679\n",
      "sample:680\n",
      "sample:681\n",
      "sample:682\n",
      "sample:683\n",
      "sample:684\n",
      "sample:685\n",
      "sample:686\n",
      "sample:687\n",
      "sample:688\n",
      "sample:689\n",
      "sample:690\n",
      "sample:691\n",
      "sample:692\n",
      "sample:693\n",
      "sample:694\n",
      "sample:695\n",
      "sample:696\n",
      "sample:697\n",
      "sample:698\n",
      "sample:699\n",
      "sample:700\n",
      "sample:701\n",
      "sample:702\n",
      "sample:703\n",
      "sample:704\n",
      "sample:705\n",
      "sample:706\n",
      "sample:707\n",
      "sample:708\n",
      "sample:709\n",
      "sample:710\n",
      "sample:711\n",
      "sample:712\n",
      "sample:713\n",
      "sample:714\n",
      "sample:715\n",
      "sample:716\n",
      "sample:717\n",
      "sample:718\n",
      "sample:719\n",
      "sample:720\n",
      "sample:721\n",
      "sample:722\n",
      "sample:723\n",
      "sample:724\n",
      "sample:725\n",
      "sample:726\n",
      "sample:727\n",
      "sample:728\n",
      "sample:729\n",
      "sample:730\n",
      "sample:731\n",
      "sample:732\n",
      "sample:733\n",
      "sample:734\n",
      "sample:735\n",
      "sample:736\n",
      "sample:737\n",
      "sample:738\n",
      "sample:739\n",
      "sample:740\n",
      "sample:741\n",
      "sample:742\n",
      "sample:743\n",
      "sample:744\n",
      "sample:745\n",
      "sample:746\n",
      "sample:747\n",
      "sample:748\n",
      "sample:749\n",
      "sample:750\n",
      "sample:751\n",
      "sample:752\n",
      "sample:753\n",
      "sample:754\n",
      "sample:755\n",
      "sample:756\n",
      "sample:757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample:758\n",
      "sample:759\n",
      "sample:760\n",
      "sample:761\n",
      "sample:762\n",
      "sample:763\n",
      "sample:764\n",
      "sample:765\n",
      "sample:766\n",
      "sample:767\n",
      "sample:768\n",
      "sample:769\n",
      "sample:770\n",
      "sample:771\n",
      "sample:772\n",
      "sample:773\n",
      "sample:774\n",
      "sample:775\n",
      "sample:776\n",
      "sample:777\n",
      "sample:778\n",
      "sample:779\n",
      "sample:780\n",
      "sample:781\n",
      "sample:782\n",
      "sample:783\n",
      "sample:784\n",
      "sample:785\n",
      "sample:786\n",
      "sample:787\n",
      "sample:788\n",
      "sample:789\n",
      "sample:790\n",
      "sample:791\n",
      "sample:792\n",
      "sample:793\n",
      "sample:794\n",
      "sample:795\n",
      "sample:796\n",
      "sample:797\n",
      "sample:798\n",
      "sample:799\n",
      "sample:800\n",
      "sample:801\n",
      "sample:802\n",
      "sample:803\n",
      "sample:804\n",
      "sample:805\n",
      "sample:806\n",
      "sample:807\n",
      "sample:808\n",
      "sample:809\n",
      "sample:810\n",
      "sample:811\n",
      "sample:812\n",
      "sample:813\n",
      "sample:814\n",
      "sample:815\n",
      "sample:816\n",
      "sample:817\n",
      "sample:818\n",
      "sample:819\n",
      "sample:820\n",
      "sample:821\n",
      "sample:822\n",
      "sample:823\n",
      "sample:824\n",
      "sample:825\n",
      "sample:826\n",
      "sample:827\n",
      "sample:828\n",
      "sample:829\n",
      "sample:830\n",
      "sample:831\n",
      "sample:832\n",
      "sample:833\n",
      "sample:834\n",
      "sample:835\n",
      "sample:836\n",
      "sample:837\n",
      "sample:838\n",
      "sample:839\n",
      "sample:840\n",
      "sample:841\n",
      "sample:842\n",
      "sample:843\n",
      "sample:844\n",
      "sample:845\n",
      "sample:846\n",
      "sample:847\n",
      "sample:848\n",
      "sample:849\n",
      "sample:850\n",
      "sample:851\n",
      "sample:852\n",
      "sample:853\n",
      "sample:854\n",
      "sample:855\n",
      "sample:856\n",
      "sample:857\n",
      "sample:858\n",
      "sample:859\n",
      "sample:860\n",
      "sample:861\n",
      "sample:862\n",
      "sample:863\n",
      "sample:864\n",
      "sample:865\n",
      "sample:866\n",
      "sample:867\n",
      "sample:868\n",
      "sample:869\n",
      "[930, 2810, 429, 650, 688, 443, 771, 822, 646, 388, 124, 373, 231, 277, 602, 286, 770, 748, 651, 603, 500, 776, 419, 629, 720, 295, 615, 392, 265, 554, 205, 135, 157, 66, 287, 193, 154, 317, 397, 418, 458, 368, 673, 319, 211, 209, 751, 582, 379, 599, 560, 699, 424, 353, 742, 442, 605, 1037, 908, 573, 684, 1160, 737, 764, 694, 171, 199, 543, 305, 329, 611, 63, 542, 644, 287, 343, 380, 237, 643, 115, 654]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "counts = [0 for i in range(81)]\n",
    "for i,g in enumerate(train_loader):\n",
    "    print(\"sample:\" + str(i))\n",
    "    # start = time.time()\n",
    "    batch_images,batch_impulses,batch_gt_responses,batch_class_ids = g\n",
    "#     print(batch_class_ids)\n",
    "    for i in batch_class_ids:\n",
    "        counts[int(i.item())] += 1\n",
    "print(counts)\n",
    "#     batch_images = np.moveaxis(batch_images.numpy(),1,-1)\n",
    "#     print(batch_images.shape)\n",
    "#     batch_impulses = batch_impulses.squeeze().numpy()*128\n",
    "#     batch_gt_responses = batch_gt_responses.squeeze().numpy()*128\n",
    "#     batch_class_ids = batch_class_ids.numpy()\n",
    "#     # s =(time.time()-start)\n",
    "#     # print(s)\n",
    "#     batch_images[0] *= 128\n",
    "#     batch_images[0] += config.MEAN_PIXEL\n",
    "#     img = Image.fromarray((batch_images[0]).astype(\"uint8\"),\"RGB\")\n",
    "#     img.show()\n",
    "#     print((np.sum(batch_gt_responses)//128)**0.5)\n",
    "#     mask = Image.fromarray(((batch_gt_responses)).astype(\"uint8\"),\"L\")\n",
    "#     mask.show()\n",
    "#     print(config.CLASS_NAMES[batch_class_ids[0]])\n",
    "#     impulse = Image.fromarray(((batch_impulses)).astype(\"uint8\"),\"L\")\n",
    "#     impulse.show()\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4952,\n",
       " 10777,\n",
       " 314,\n",
       " 1919,\n",
       " 367,\n",
       " 146,\n",
       " 283,\n",
       " 222,\n",
       " 414,\n",
       " 424,\n",
       " 634,\n",
       " 101,\n",
       " 75,\n",
       " 60,\n",
       " 411,\n",
       " 427,\n",
       " 202,\n",
       " 218,\n",
       " 272,\n",
       " 354,\n",
       " 374,\n",
       " 252,\n",
       " 72,\n",
       " 266,\n",
       " 252,\n",
       " 377,\n",
       " 417,\n",
       " 541,\n",
       " 254,\n",
       " 305,\n",
       " 119,\n",
       " 243,\n",
       " 69,\n",
       " 263,\n",
       " 336,\n",
       " 148,\n",
       " 148,\n",
       " 180,\n",
       " 267,\n",
       " 229,\n",
       " 1015,\n",
       " 353,\n",
       " 895,\n",
       " 217,\n",
       " 325,\n",
       " 253,\n",
       " 624,\n",
       " 379,\n",
       " 239,\n",
       " 177,\n",
       " 285,\n",
       " 312,\n",
       " 369,\n",
       " 127,\n",
       " 284,\n",
       " 334,\n",
       " 310,\n",
       " 1771,\n",
       " 263,\n",
       " 342,\n",
       " 166,\n",
       " 703,\n",
       " 186,\n",
       " 289,\n",
       " 231,\n",
       " 106,\n",
       " 296,\n",
       " 155,\n",
       " 262,\n",
       " 55,\n",
       " 143,\n",
       " 12,\n",
       " 231,\n",
       " 127,\n",
       " 1129,\n",
       " 269,\n",
       " 274,\n",
       " 40,\n",
       " 204,\n",
       " 13,\n",
       " 284]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(c) for c in train_cid.class_wise_instance_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
