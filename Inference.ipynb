{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_lib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*output shape of zoom.*')\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(model_lib)\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 1\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    # not going to use these\n",
    "    N_DISTORTIONS = 0\n",
    "    MAX_DISTORTION = 0.3\n",
    "    MIN_DISTORTION = -0.1\n",
    "    \n",
    "    VALIDATION_STEPS = 20\n",
    "    # including gt\n",
    "    NUM_CLASSES = 81\n",
    "    # only flips\n",
    "    IMAGE_AUGMENT = True\n",
    "\n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9],dtype=np.float32)\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    CLASS_NAMES = [\n",
    "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    LEARNING_RATE = 0.05\n",
    "    LEARNING_MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "    MASK_SHAPE = (64,64)\n",
    "    GRID_WIDTH = 16\n",
    "    GRID_HEIGHT = 16\n",
    "    CLUE_SHAPE = (20,20)\n",
    "    GRID_SHAPE = (GRID_WIDTH, GRID_HEIGHT)\n",
    "    GRID_RESOLUTION = (1, 1)\n",
    "    IS_PADDED = True\n",
    "    MASK_THRESOLD = 0.7\n",
    "    def __init__(self):\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT,3)\n",
    "        self.MAX_BATCH_SIZE = self.BATCH_SIZE*32\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4214510917663574\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/media/data/nishanth/aravind/\"\n",
    "config = ProposalConfig()\n",
    "model_dir = \"./models/\"\n",
    "train_dataset,val_dataset = None,None\n",
    "train_pickle = root_dir+\"val_cid.pickle\"\n",
    "val_pickle = root_dir+\"val_cid.pickle\"\n",
    "class ClassInstancesDataset():\n",
    "    def __init__(self):\n",
    "        self.class_wise_instance_info = [[] for i in range(81)]\n",
    "        self.instance_info = []\n",
    "import time\n",
    "start = time.time()\n",
    "with open(train_pickle,\"rb\") as train_ann:\n",
    "    train_cid = pickle.load(train_ann)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "#     train_dataset = model_lib.CocoDataset(train_cid,config)\n",
    "with open(val_pickle,\"rb\") as val_ann:\n",
    "    val_cid = pickle.load(val_ann)\n",
    "#     val_dataset = model_lib.CocoDataset(val_cid,config)\n",
    "train_loader = model_lib.get_loader(train_cid,config,\"ins\")\n",
    "val_loader = model_lib.get_loader(val_cid,config,\"ins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4362, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1634, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1622, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       3.5993, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.0619, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.7261, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1053, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.1138, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.8198, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       1.7935, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4731, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1952, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1698, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.3650, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.9655, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.8209, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1070, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       1.2578, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-03 *\n",
      "       7.8063, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-03 *\n",
      "       6.3054, device='cuda:0') tensor(26, device='cuda:0') umbrella\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5671, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2406, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.1819, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       1.9898, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       1.9470, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5352, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2451, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1247, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       1.4236, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       1.2025, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5876, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2528, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.2828, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.1052, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.7735, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4369, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.2418, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       3.5817, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.3921, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.9522, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4272, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.3163, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1224, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       1.6358, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.4609, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4008, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2601, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.0875, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       4.9673, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.9300, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.7808, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       6.6789, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.0355, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       1.4744, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.4536, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4993, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2096, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       4.4676, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.8839, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.7012, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4517, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2355, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.9440, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       6.1550, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       3.0709, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6976, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1292, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       4.4118, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       2.2350, device='cuda:0') tensor(74, device='cuda:0') book\n",
      "tensor(1.00000e-02 *\n",
      "       1.6303, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6191, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1204, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.3473, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       5.3426, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.6210, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6339, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1268, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.5283, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       3.6253, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.8023, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6928, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1155, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.4063, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.8343, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       1.3488, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4024, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.3779, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.1936, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.8991, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.6702, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6988, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1254, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.1405, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.3686, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       2.2122, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5542, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2005, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1166, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.1447, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.0428, device='cuda:0') tensor(17, device='cuda:0') dog\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3787, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2775, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1181, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       3.3373, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.2553, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5319, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1941, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.3203, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       5.9853, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.8357, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5065, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.2955, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       2.7388, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.4596, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.1313, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.8165, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       4.6212, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.4150, device='cuda:0') tensor(9, device='cuda:0') boat\n",
      "tensor(1.00000e-02 *\n",
      "       1.4353, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.3914, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5935, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2240, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.3710, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.5272, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.1596, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4999, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1942, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.3078, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       5.2191, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.8683, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4934, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1186, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.0237, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       5.4146, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       5.3808, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.7056, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       9.4908, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.3913, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.0600, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.0340, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3355, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.3251, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       9.2708, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       7.1419, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.2240, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4445, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1689, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.4959, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       6.8960, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       6.6391, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.2907, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.2399, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       7.8896, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       6.8770, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       6.7021, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5011, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2233, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.2480, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       4.7065, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       4.0339, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5465, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1768, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.9326, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       3.6809, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.1012, device='cuda:0') tensor(34, device='cuda:0') kite\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5150, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2201, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.1397, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.6512, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.6253, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5125, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1906, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.7748, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.3012, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       2.7293, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4462, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2126, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1256, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       4.2800, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.4315, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5006, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.3528, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       8.3155, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-03 *\n",
      "       8.7458, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "tensor(1.00000e-03 *\n",
      "       6.9945, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4989, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1313, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       9.1088, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.3422, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       3.3139, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5614, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2077, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.7013, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.5048, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.1160, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5172, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1768, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.3070, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       4.5105, device='cuda:0') tensor(14, device='cuda:0') bench\n",
      "tensor(1.00000e-02 *\n",
      "       4.1257, device='cuda:0') tensor(61, device='cuda:0') dining table\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5987, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2000, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       6.9277, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.2159, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.8326, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6278, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1166, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       9.6499, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.0840, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.2640, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4242, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2202, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.1511, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       7.0569, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       5.2581, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4849, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2521, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1071, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.2305, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.1595, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5680, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1976, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       7.5589, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.2928, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.6957, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5415, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       9.9440, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.6345, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       4.2082, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.1619, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4044, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.3306, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       8.5986, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       3.6586, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.5598, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3064, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.2064, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1625, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       9.1749, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       5.4709, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5570, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1690, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1564, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       3.7263, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.3902, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6688, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1604, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.9666, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.6821, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.7819, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5652, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1848, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1177, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.1382, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       1.4697, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4697, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.3540, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       6.5431, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.9311, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.0930, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.7466, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1287, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       1.5893, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       1.4302, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.3556, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3000, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2647, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       8.5414, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       7.7667, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       4.7648, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6978, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1130, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       4.6420, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.5633, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.7320, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3641, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.3279, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1537, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.4574, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       2.0514, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.7940, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       7.4611, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.4180, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       2.0314, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.3346, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6048, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1357, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.8942, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       3.2739, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.6604, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.7266, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1578, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       1.9612, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       1.3977, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       1.2414, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.2632, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.2534, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2412, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.0919, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.5899, device='cuda:0') tensor(3, device='cuda:0') car\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4629, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2159, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1188, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.1415, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.1642, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6345, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1443, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.4634, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-02 *\n",
      "       2.4253, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.1117, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4513, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.2284, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       8.9759, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       3.9543, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       2.6900, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6244, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1261, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       9.6517, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.7686, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       1.9783, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4247, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1794, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1169, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       7.3395, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       2.5284, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.8994, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       3.0035, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       2.2561, device='cuda:0') tensor(17, device='cuda:0') dog\n",
      "tensor(1.00000e-03 *\n",
      "       4.3016, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-03 *\n",
      "       4.0596, device='cuda:0') tensor(18, device='cuda:0') horse\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3636, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1584, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(0.1056, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       6.1271, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.4828, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.2839, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.2666, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.2063, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       4.5915, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       3.3870, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.6667, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(0.1299, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       7.7736, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       1.9304, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       1.6457, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3564, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.3385, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.5761, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       5.7613, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.1392, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3556, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.3066, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1039, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.4052, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       4.3482, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3390, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.3244, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       9.6517, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       6.0629, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       4.0794, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4049, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2572, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.7541, device='cuda:0') tensor(61, device='cuda:0') dining table\n",
      "tensor(1.00000e-02 *\n",
      "       4.6373, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       4.1175, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5984, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1311, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       5.7133, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       4.7526, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.4505, device='cuda:0') tensor(60, device='cuda:0') bed\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.5147, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.1886, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(1.00000e-02 *\n",
      "       6.8789, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       6.1176, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       3.9568, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.3655, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(0.2716, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.1075, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       4.7180, device='cuda:0') tensor(8, device='cuda:0') truck\n",
      "tensor(1.00000e-02 *\n",
      "       3.4573, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "\n",
      "torch.Size([5]) torch.Size([5])\n",
      "tensor(0.4120, device='cuda:0') tensor(57, device='cuda:0') chair\n",
      "tensor(0.3381, device='cuda:0') tensor(1, device='cuda:0') person\n",
      "tensor(1.00000e-02 *\n",
      "       5.7280, device='cuda:0') tensor(0, device='cuda:0') BG\n",
      "tensor(1.00000e-02 *\n",
      "       2.6396, device='cuda:0') tensor(3, device='cuda:0') car\n",
      "tensor(1.00000e-02 *\n",
      "       2.6212, device='cuda:0') tensor(8, device='cuda:0') truck\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "net = model_lib.SimpleHGModel()\n",
    "net.load_state_dict(torch.load(model_dir+\"model_bce_0_7600.pt\"))\n",
    "net = net.cuda()\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(val_loader):\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_class_ids = data\n",
    "        a,b,c= batch_images.numpy(), batch_impulses.numpy(),batch_gt_responses.numpy()\n",
    "        a = np.moveaxis(a,1,-1)\n",
    "        b = np.moveaxis(b,1,-1)\n",
    "        c = np.moveaxis(c,1,-1)\n",
    "        Image.fromarray((a[0]*128 + config.MEAN_PIXEL).astype(np.uint8),\"RGB\").show()\n",
    "        Image.fromarray((b[0][:,:,0]*128).astype(np.uint8),\"L\").show()\n",
    "        Image.fromarray((c[0][:,:,0]*128).astype(np.uint8),\"L\").show()\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_class_ids = batch_images.cuda(),batch_impulses.cuda(),batch_gt_responses.cuda(),batch_class_ids.cuda()\n",
    "        pred_class = net([batch_images,batch_impulses])\n",
    "#         print(pred_class)\n",
    "        pred_class = F.softmax(pred_class,dim=-1).squeeze()\n",
    "        maxs, indices = torch.topk(pred_class,5,-1)\n",
    "        print(maxs.shape,indices.shape)\n",
    "        for i in range(5):\n",
    "            print(maxs[i],indices[i],config.CLASS_NAMES[int(indices[i])])\n",
    "#         print(batch_class_ids)\n",
    "#         print(indices)\n",
    "#         print(\"gt_class:\",config.CLASS_NAMES[int(batch_class_ids[0])])\n",
    "#         print(\"pred_class: \",pred_class[int(batch_class_ids[0])])\n",
    "#         print(config.CLASS_NAMES[int(indices[0])])\n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.8727030754089355\n",
      "1.0894262790679932\n",
      "0.7940988540649414\n",
      "0.006885528564453125\n",
      "0.007991790771484375\n",
      "0.008913755416870117\n",
      "0.02939128875732422\n",
      "0.010446310043334961\n",
      "0.0075948238372802734\n",
      "0.006993293762207031\n",
      "0.007034778594970703\n",
      "0.009102106094360352\n",
      "0.007321357727050781\n",
      "0.0072498321533203125\n",
      "0.0072939395904541016\n",
      "0.007134437561035156\n",
      "3.5132102966308594\n",
      "1.0766754150390625\n",
      "0.6235623359680176\n",
      "0.010315656661987305\n",
      "0.007702350616455078\n",
      "0.012910842895507812\n",
      "0.008159875869750977\n",
      "0.00718235969543457\n",
      "0.02111506462097168\n",
      "0.007714271545410156\n",
      "0.008462667465209961\n",
      "0.008092164993286133\n",
      "0.011322259902954102\n",
      "0.010010242462158203\n",
      "1.5816411972045898\n",
      "0.007668018341064453\n",
      "2.0190937519073486\n",
      "1.1086020469665527\n",
      "1.0073204040527344\n",
      "0.025751352310180664\n",
      "0.00955820083618164\n",
      "0.00836324691772461\n",
      "0.0075795650482177734\n",
      "0.007452249526977539\n",
      "0.010152816772460938\n",
      "0.012168169021606445\n",
      "0.009928703308105469\n",
      "0.00722956657409668\n",
      "0.012662649154663086\n",
      "0.04663562774658203\n",
      "0.6680276393890381\n",
      "0.017316341400146484\n",
      "1.54194974899292\n",
      "3.0989315509796143\n",
      "0.009104728698730469\n",
      "0.008269786834716797\n",
      "0.009071588516235352\n",
      "0.008842706680297852\n",
      "0.011053323745727539\n",
      "0.008454084396362305\n",
      "0.00838780403137207\n",
      "0.009987115859985352\n",
      "0.013566732406616211\n",
      "0.010347843170166016\n",
      "0.8920626640319824\n",
      "0.000255584716796875\n",
      "0.028026819229125977\n",
      "0.009157657623291016\n",
      "2.1408140659332275\n",
      "1.477217435836792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-8:\n",
      "Process Process-2:\n",
      "Process Process-4:\n",
      "Process Process-5:\n",
      "Process Process-7:\n",
      "Process Process-14:\n",
      "Process Process-16:\n",
      "Process Process-10:\n",
      "Traceback (most recent call last):\n",
      "Process Process-1:\n",
      "Process Process-13:\n",
      "Process Process-12:\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Process Process-11:\n",
      "Process Process-15:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "Process Process-9:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Process Process-6:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 176, in __getitem__\n",
      "    impulse, gt_response, class_id, is_bad_image = self.generate_targets(masks, class_id)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 203, in generate_targets\n",
      "    if np.sum(umask) / np.sum(mask) < 0.3:\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n",
      "    padding=config.IS_PADDED)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/core/fromnumeric.py\", line 1882, in sum\n",
      "    out=out, **kwargs)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 229, in resize_image\n",
      "    image, (round(h * scale), round(w * scale)))\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/core/_methods.py\", line 32, in _sum\n",
      "    return umr_sum(a, axis, dtype, out, keepdims)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n",
      "    padding=config.IS_PADDED)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 229, in resize_image\n",
      "    image, (round(h * scale), round(w * scale)))\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n",
      "    padding=config.IS_PADDED)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/lib/utils.py\", line 101, in newfunc\n",
      "    return func(*args, **kwds)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 564, in imresize\n",
      "    imnew = im.resize(size, resample=func[interp])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 179, in __getitem__\n",
      "    image = image.astype(np.float32)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 186, in __getitem__\n",
      "    gt_response = np.moveaxis(np.expand_dims(gt_response, -1), 2, 0).astype(np.float32)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/lib/utils.py\", line 101, in newfunc\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 239, in resize_image\n",
      "    image = np.pad(image, padding, mode='constant', constant_values=0)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n",
      "    samples = collate_fn([dataset[i] for i in batch_indices])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 564, in imresize\n",
      "    imnew = im.resize(size, resample=func[interp])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n",
      "    padding=config.IS_PADDED)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 264, in load_image_gt\n",
      "    masks = maskUtils.decode(mask_obj)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/lib/arraypad.py\", line 1301, in pad\n",
      "    pad_width = _validate_lengths(narray, pad_width)\n",
      "  File \"/home/aravind/re/model_lib.py\", line 229, in resize_image\n",
      "    image, (round(h * scale), round(w * scale)))\n",
      "  File \"/home/aravind/re/model_lib.py\", line 263, in load_image_gt\n",
      "    image = self.read_image(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 2910, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-4-72c191e434fa>\", line 8, in <module>\n",
      "    g = next(train_loader)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 280, in __next__\n",
      "    idx, batch = self._get_batch()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 259, in _get_batch\n",
      "    return self.data_queue.get()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/queues.py\", line 335, in get\n",
      "    res = self._reader.recv_bytes()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 216, in recv_bytes\n",
      "    buf = self._recv_bytes(maxlength)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 407, in _recv_bytes\n",
      "    buf = self._recv(4)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/multiprocessing/connection.py\", line 379, in _recv\n",
      "    chunk = read(handle, remaining)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/IPython/core/interactiveshell.py\", line 1828, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 1090, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 311, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/IPython/core/ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/inspect.py\", line 1459, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/inspect.py\", line 1417, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/inspect.py\", line 677, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/inspect.py\", line 720, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/inspect.py\", line 689, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/inspect.py\", line 674, in getsourcefile\n",
      "    if os.path.exists(filename):\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/genericpath.py\", line 19, in exists\n",
      "    os.stat(path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 178, in handler\n",
      "    _error_if_any_worker_fails()\n",
      "RuntimeError: DataLoader worker (pid 133575) exited unexpectedly with exit code 1.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/lib/utils.py\", line 101, in newfunc\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/lib/arraypad.py\", line 1084, in _validate_lengths\n",
      "    if (chk[0] < 0) or (chk[1] < 0):\n",
      "  File \"/home/aravind/re/model_lib.py\", line 175, in __getitem__\n",
      "    image, masks, class_id = self.load_image_gt(instance_index)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/pycocotools/mask.py\", line 89, in decode\n",
      "    return _mask.decode(rleObjs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 564, in imresize\n",
      "    imnew = im.resize(size, resample=func[interp])\n",
      "  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n",
      "    padding=config.IS_PADDED)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/re/model_lib.py\", line 250, in read_image\n",
      "    image = skimage.io.imread(image_path)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_io.py\", line 61, in imread\n",
      "    img = call_plugin('imread', fname, plugin=plugin, **plugin_args)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/manage_plugins.py\", line 211, in call_plugin\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/re/model_lib.py\", line 229, in resize_image\n",
      "    image, (round(h * scale), round(w * scale)))\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/numpy/lib/utils.py\", line 101, in newfunc\n",
      "    return func(*args, **kwds)\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 37, in imread\n",
      "    return pil_to_ndarray(im, dtype=dtype, img_num=img_num)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/skimage/io/_plugins/pil_plugin.py\", line 53, in pil_to_ndarray\n",
      "    im.getdata()[0]\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/scipy/misc/pilutil.py\", line 564, in imresize\n",
      "    imnew = im.resize(size, resample=func[interp])\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1749, in resize\n",
      "    return self._new(self.im.resize(size, resample, box))\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/Image.py\", line 1220, in getdata\n",
      "    self.load()\n",
      "  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/PIL/ImageFile.py\", line 231, in load\n",
      "    n, err_code = decoder.decode(b)\n",
      "KeyboardInterrupt\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "counts = [0 for i in range(81)]\n",
    "train_loader = iter(train_loader)\n",
    "for i in range(1000):\n",
    "    start = time.time()\n",
    "    g = next(train_loader)\n",
    "    print(time.time()-start)\n",
    "for i,g in enumerate(train_loader):\n",
    "    print(\"sample:\" + str(i))\n",
    "#     start = time.time()\n",
    "    batch_images,batch_impulses,batch_gt_responses,batch_class_ids = g\n",
    "#     print(batch_class_ids)\n",
    "    for i in batch_class_ids:\n",
    "        counts[int(i.item())] += 1\n",
    "print(counts)\n",
    "#     batch_images = np.moveaxis(batch_images.numpy(),1,-1)\n",
    "#     print(batch_images.shape)\n",
    "#     batch_impulses = batch_impulses.squeeze().numpy()*128\n",
    "#     batch_gt_responses = batch_gt_responses.squeeze().numpy()*128\n",
    "#     batch_class_ids = batch_class_ids.numpy()\n",
    "#     # s =(time.time()-start)\n",
    "#     # print(s)\n",
    "#     batch_images[0] *= 128\n",
    "#     batch_images[0] += config.MEAN_PIXEL\n",
    "#     img = Image.fromarray((batch_images[0]).astype(\"uint8\"),\"RGB\")\n",
    "#     img.show()\n",
    "#     print((np.sum(batch_gt_responses)//128)**0.5)\n",
    "#     mask = Image.fromarray(((batch_gt_responses)).astype(\"uint8\"),\"L\")\n",
    "#     mask.show()\n",
    "#     print(config.CLASS_NAMES[batch_class_ids[0]])\n",
    "#     impulse = Image.fromarray(((batch_impulses)).astype(\"uint8\"),\"L\")\n",
    "#     impulse.show()\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(c) for c in train_cid.class_wise_instance_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
