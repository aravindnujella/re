{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model_lib\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', '.*output shape of zoom.*')\n",
    "import pickle\n",
    "import importlib\n",
    "importlib.reload(model_lib)\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config to train\n",
    "# TODO: check Config is correct\n",
    "class ProposalConfig():\n",
    "    NAME = \"InSegm\"\n",
    "    GPU_COUNT = 1\n",
    "    # online training\n",
    "    IMAGES_PER_GPU = 64\n",
    "    STEPS_PER_EPOCH = 100\n",
    "    # not going to use these\n",
    "    N_DISTORTIONS = 0\n",
    "    MAX_DISTORTION = 0.3\n",
    "    MIN_DISTORTION = -0.1\n",
    "    \n",
    "    VALIDATION_STEPS = 20\n",
    "    # including gt\n",
    "    NUM_CLASSES = 81\n",
    "    # only flips\n",
    "    IMAGE_AUGMENT = True\n",
    "\n",
    "    MEAN_PIXEL = np.array([123.7, 116.8, 103.9],dtype=np.float32)\n",
    "    MAX_GT_INSTANCES = 100\n",
    "    DETECTION_MAX_INSTANCES = 100\n",
    "    DETECTION_MIN_CONFIDENCE = 0.7\n",
    "    CLASS_NAMES = [\n",
    "        'BG', 'person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
    "        'train', 'truck', 'boat', 'traffic light', 'fire hydrant', 'stop sign',\n",
    "        'parking meter', 'bench', 'bird', 'cat', 'dog', 'horse', 'sheep',\n",
    "        'cow', 'elephant', 'bear', 'zebra', 'giraffe', 'backpack', 'umbrella',\n",
    "        'handbag', 'tie', 'suitcase', 'frisbee', 'skis', 'snowboard',\n",
    "        'sports ball', 'kite', 'baseball bat', 'baseball glove', 'skateboard',\n",
    "        'surfboard', 'tennis racket', 'bottle', 'wine glass', 'cup', 'fork',\n",
    "        'knife', 'spoon', 'bowl', 'banana', 'apple', 'sandwich', 'orange',\n",
    "        'broccoli', 'carrot', 'hot dog', 'pizza', 'donut', 'cake', 'chair',\n",
    "        'couch', 'potted plant', 'bed', 'dining table', 'toilet', 'tv',\n",
    "        'laptop', 'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
    "        'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock', 'vase',\n",
    "        'scissors', 'teddy bear', 'hair drier', 'toothbrush'\n",
    "    ]\n",
    "    DETECTION_NMS_THRESHOLD = 0.3\n",
    "    LEARNING_RATE = 0.05\n",
    "    LEARNING_MOMENTUM = 0.9\n",
    "    WEIGHT_DECAY = 0.0001\n",
    "    WIDTH = 224\n",
    "    HEIGHT = 224\n",
    "    MASK_SHAPE = (64,64)\n",
    "    GRID_WIDTH = 16\n",
    "    GRID_HEIGHT = 16\n",
    "    CLUE_SHAPE = (20,20)\n",
    "    GRID_SHAPE = (GRID_WIDTH, GRID_HEIGHT)\n",
    "    GRID_RESOLUTION = (1, 1)\n",
    "    IS_PADDED = True\n",
    "    MASK_THRESOLD = 0.7\n",
    "    def __init__(self):\n",
    "        self.BATCH_SIZE = self.IMAGES_PER_GPU * self.GPU_COUNT\n",
    "        self.IMAGE_SHAPE = (self.WIDTH, self.HEIGHT,3)\n",
    "        self.MAX_BATCH_SIZE = self.BATCH_SIZE*32\n",
    "\n",
    "    def display(self):\n",
    "        \"\"\"Display Configuration values.\"\"\"\n",
    "        print(\"\\nConfigurations:\")\n",
    "        for a in dir(self):\n",
    "            if not a.startswith(\"__\") and not callable(getattr(self, a)):\n",
    "                print(\"{:30} {}\".format(a, getattr(self, a)))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.609081506729126\n"
     ]
    }
   ],
   "source": [
    "root_dir = \"/media/data/nishanth/aravind/\"\n",
    "config = ProposalConfig()\n",
    "model_dir = \"./models/\"\n",
    "train_dataset,val_dataset = None,None\n",
    "train_pickle = root_dir+\"val_cid.pickle\"\n",
    "val_pickle = root_dir+\"val_cid.pickle\"\n",
    "class ClassInstancesDataset():\n",
    "    def __init__(self):\n",
    "        self.class_wise_instance_info = [[] for i in range(81)]\n",
    "        self.instance_info = []\n",
    "import time\n",
    "start = time.time()\n",
    "with open(train_pickle,\"rb\") as train_ann:\n",
    "    train_cid = pickle.load(train_ann)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "#     train_dataset = model_lib.CocoDataset(train_cid,config)\n",
    "with open(val_pickle,\"rb\") as val_ann:\n",
    "    val_cid = pickle.load(val_ann)\n",
    "#     val_dataset = model_lib.CocoDataset(val_cid,config)\n",
    "train_loader = model_lib.get_loader(train_cid,config,\"ins\")\n",
    "val_loader = model_lib.get_loader(val_cid,config,\"ins\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5572962760925293  batch_collate\n",
      "0.5886411666870117  batch_collate\n",
      "0.4985029697418213  batch_collate\n",
      "0.218580961227417  batch_collate\n",
      "0.3834507465362549  batch_collate\n",
      "0.37436676025390625  batch_collate\n",
      "0.3261082172393799  batch_collate\n",
      "0.38337135314941406  batch_collate\n",
      "0.3203256130218506  batch_collate\n",
      "10.291091918945312 10.291091918945312\n",
      "0.46692442893981934  batch_collate\n",
      "0.33815646171569824  batch_collate\n",
      "0.4394052028656006  batch_collate\n",
      "0.8688719272613525 5.5799819231033325\n",
      "0.49556684494018555  batch_collate\n",
      "0.4511990547180176  batch_collate\n",
      "0.44844698905944824  batch_collate\n",
      "0.6621518135070801  batch_collate\n",
      "0.40909433364868164  batch_collate\n",
      "0.44199204444885254 3.867318630218506\n",
      "0.24059700965881348  batch_collate\n",
      "0.19628524780273438  batch_collate\n",
      "0.22516345977783203  batch_collate\n",
      "0.2516777515411377  batch_collate\n",
      "0.3268313407897949  batch_collate\n",
      "0.5092175006866455  batch_collate\n",
      "0.3013496398925781  batch_collate\n",
      "0.20308947563171387  batch_collate\n",
      "0.3153672218322754  batch_collate\n",
      "0.1802206039428711  batch_collate\n",
      "0.49686121940612793  batch_collate\n",
      "0.6559851169586182  batch_collate\n",
      "0.38688135147094727  batch_collate\n",
      "0.5440428256988525  batch_collate\n",
      "0.31237292289733887  batch_collate\n",
      "4.2190775871276855 3.955258369445801\n",
      "0.06493544578552246 3.177193784713745\n",
      "0.0001671314239501953 2.6476893424987793\n",
      "0.0895843505859375 2.282245772225516\n",
      "0.009856939315795898 1.9981971681118011\n",
      "0.08470273017883301 1.785586675008138\n",
      "0.00019168853759765625 1.607047176361084\n",
      "0.08074545860290527 1.468292474746704\n",
      "0.0001773834228515625 1.3459495504697163\n",
      "0.07232308387756348 1.2479782838087816\n",
      "0.00031113624572753906 1.158859201839992\n",
      "0.03253889083862305 1.0837711811065673\n",
      "0.0001659393310546875 1.0160458534955978\n",
      "0.08814167976379395 0.9614632550407859\n",
      "0.0001773834228515625 0.9080584843953451\n",
      "0.0794069766998291 0.8644452471482126\n",
      "0.00033593177795410156 0.8212397813796997\n",
      "0.09782171249389648 0.7867913019089472\n",
      "0.0001780986785888672 0.7510361563075673\n",
      "0.10050249099731445 0.7227520839027737\n",
      "0.0002684593200683594 0.6926485995451609\n",
      "0.12519359588623047 0.6699503993988037\n",
      "0.00019025802612304688 0.6441903939613929\n",
      "0.18461132049560547 0.6271689467959933\n",
      "0.0006864070892333984 0.6047945703778949\n",
      "0.1219639778137207 0.5881452395998198\n",
      "0.00019025802612304688 0.56854674021403\n",
      "0.12908244132995605 0.5543704725080921\n",
      "0.0005786418914794922 0.5370644778013229\n",
      "0.1343388557434082  batch_collate\n",
      "0.17066168785095215  batch_collate\n",
      "0.3767566680908203  batch_collate\n",
      "0.18924570083618164  batch_collate\n",
      "0.373401403427124  batch_collate\n",
      "2.0027823448181152 0.5814801707412257\n",
      "0.1391770839691162 0.568471256424399\n",
      "0.27652597427368164  batch_collate\n",
      "0.42891836166381836  batch_collate\n",
      "0.10844779014587402  batch_collate\n",
      "0.09516263008117676  batch_collate\n",
      "0.12822365760803223  batch_collate\n",
      "0.19550418853759766  batch_collate\n",
      "0.11275649070739746  batch_collate\n",
      "0.2584407329559326  batch_collate\n",
      "0.43909740447998047  batch_collate\n",
      "0.25699543952941895  batch_collate\n",
      "0.281771183013916  batch_collate\n",
      "0.1840221881866455  batch_collate\n",
      "0.12414789199829102  batch_collate\n",
      "0.2198338508605957  batch_collate\n",
      "0.4126136302947998  batch_collate\n",
      "4.273205995559692 0.6743208203996931\n",
      "0.3391132354736328  batch_collate\n",
      "0.22280478477478027  batch_collate\n",
      "0.22273683547973633  batch_collate\n",
      "0.19888091087341309  batch_collate\n",
      "0.1335313320159912  batch_collate\n",
      "0.07624125480651855  batch_collate\n",
      "0.4510350227355957  batch_collate\n",
      "0.1662142276763916  batch_collate\n",
      "0.20920348167419434  batch_collate\n",
      "0.28926777839660645  batch_collate\n",
      "0.31966304779052734  batch_collate\n",
      "2.5806422233581543 0.7272741927040948\n",
      "0.04184985160827637 0.7087492105123159\n",
      "0.0004177093505859375 0.6901089078501651\n",
      "0.0832059383392334  batch_collate\n",
      "0.12467217445373535  batch_collate\n",
      "2.0165092945098877 0.7241191741747733\n",
      "0.014606714248657227 0.7063813626766204\n",
      "0.03575468063354492 0.6900246143341064\n",
      "0.0002970695495605469 0.6736025299344744\n",
      "0.06456160545349121 0.6594387875046841\n",
      "0.00018715858459472656 0.6444557959383185\n",
      "0.06911110877990723 0.6316703584459092\n",
      "0.00019025802612304688 0.6179425301759139\n",
      "0.036368370056152344 0.6055686118754935\n",
      "0.00017762184143066406 0.5929562995831171\n",
      "0.03397727012634277 0.581548564288081\n",
      "0.0003886222839355469 0.5699253654479981\n",
      "0.17215776443481445  batch_collate\n",
      "0.1370997428894043  batch_collate\n",
      "0.2627604007720947  batch_collate\n",
      "0.8681530952453613 0.5757729679930443\n",
      "0.00028634071350097656 0.5647059174684378\n",
      "0.157179594039917 0.557016741554692\n",
      "0.00019598007202148438 0.5467052459716797\n",
      "0.07746243476867676 0.5381735584952615\n",
      "0.009978294372558594 0.528741500207356\n",
      "0.07404923439025879 0.5207644429123193\n",
      "0.00022721290588378906 0.511789663084622\n",
      "0.15139532089233398 0.5056812844033969\n",
      "0.015815019607543945 0.4975168466567993\n",
      "0.021867752075195312 0.4897193205161173\n",
      "0.1166696548461914  batch_collate\n",
      "0.016834020614624023 0.4820921382596416\n",
      "0.07369685173034668 0.4756096733940972\n",
      "0.00022101402282714844 0.4681817255914211\n",
      "0.4163534641265869  batch_collate\n",
      "0.12964177131652832  batch_collate\n",
      "0.13474535942077637  batch_collate\n",
      "0.31950998306274414  batch_collate\n",
      "0.5253951549530029  batch_collate\n",
      "2.262730836868286 0.49579017345721904\n",
      "0.2252824306488037  batch_collate\n",
      "0.13672494888305664  batch_collate\n",
      "0.40203022956848145 0.49436956824678363\n",
      "0.24331951141357422  batch_collate\n",
      "0.12745451927185059  batch_collate\n",
      "0.1751852035522461  batch_collate\n",
      "0.58980393409729 0.49579396176694046\n",
      "0.2686011791229248  batch_collate\n",
      "0.21396255493164062  batch_collate\n",
      "0.10304999351501465  batch_collate\n",
      "0.2987494468688965  batch_collate\n",
      "0.13236260414123535  batch_collate\n",
      "0.22757482528686523  batch_collate\n",
      "0.09889507293701172  batch_collate\n",
      "0.17376136779785156  batch_collate\n",
      "0.11194443702697754  batch_collate\n",
      "2.0799708366394043 0.5190906805150649\n",
      "0.16846156120300293  batch_collate\n",
      "0.19727802276611328  batch_collate\n",
      "0.4877047538757324  batch_collate\n",
      "0.3380165100097656  batch_collate\n",
      "0.13110661506652832  batch_collate\n",
      "0.24158906936645508  batch_collate\n",
      "0.07841730117797852  batch_collate\n",
      "0.09383749961853027  batch_collate\n",
      "0.14153575897216797  batch_collate\n",
      "0.31362223625183105  batch_collate\n",
      "0.06366682052612305  batch_collate\n",
      "0.11569976806640625  batch_collate\n",
      "0.19349026679992676  batch_collate\n",
      "5.6356751918792725 0.5932440792304882\n",
      "0.00023889541625976562 0.5847725766045707\n",
      "0.06569838523864746 0.5774616725008253\n",
      "0.0002734661102294922 0.5694451696342893\n",
      "0.05286884307861328 0.5623687815992799\n",
      "0.00027441978454589844 0.5547729118450268\n",
      "0.03449678421020508 0.5478358968098959\n",
      "0.00027108192443847656 0.5406310966140345\n",
      "0.16794276237487793  batch_collate\n",
      "0.08902907371520996  batch_collate\n",
      "0.11119484901428223  batch_collate\n",
      "0.07403087615966797 0.5345713534912506\n",
      "0.01460719108581543 0.5279051462809244\n",
      "0.057826995849609375 0.5219547899463509\n",
      "0.00034737586975097656 0.5154346972703934\n",
      "0.041281700134277344 0.5095809565650092\n",
      "0.0205380916595459 0.5036170191881133\n",
      "0.14736628532409668  batch_collate\n",
      "0.2337322235107422  batch_collate\n",
      "0.11756348609924316  batch_collate\n",
      "1.094398021697998 0.5107348625918469\n",
      "0.0002846717834472656 0.5046580746060326\n",
      "0.03652000427246094 0.49915056789622586\n",
      "0.0003387928009033203 0.4933504309765128\n",
      "0.02961874008178711 0.4880201816558838\n",
      "0.016585111618041992 0.4826629649509083\n",
      "0.04384207725524902 0.477732393179047\n",
      "0.023551225662231445 0.4726859357621935\n",
      "0.031197309494018555 0.4678344123966091\n",
      "0.09778237342834473  batch_collate\n",
      "0.027987241744995117 0.46305346488952637\n",
      "0.12315249443054199 0.4593986157448061\n",
      "0.0194089412689209 0.45471787452697754\n",
      "0.08226490020751953 0.4507973169025622\n",
      "0.0005848407745361328 0.4461076036095619\n",
      "0.09566974639892578 0.4424948421950193\n",
      "0.0052907466888427734 0.438033575914344\n",
      "0.07942533493041992 0.43441127044985994\n",
      "0.21657848358154297  batch_collate\n",
      "0.2025601863861084  batch_collate\n",
      "0.32671260833740234  batch_collate\n",
      "0.20808100700378418  batch_collate\n",
      "0.11545538902282715  batch_collate\n",
      "0.2076559066772461  batch_collate\n",
      "0.23745465278625488  batch_collate\n",
      "0.16646790504455566  batch_collate\n",
      "0.10273528099060059  batch_collate\n",
      "1.8645296096801758 0.4487124538421631\n",
      "0.11879396438598633  batch_collate\n",
      "0.46570873260498047  batch_collate\n",
      "0.21264982223510742  batch_collate\n",
      "0.10085082054138184  batch_collate\n",
      "0.37631702423095703  batch_collate\n",
      "0.14768052101135254  batch_collate\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3692631721496582  batch_collate\n",
      "0.24700593948364258  batch_collate\n",
      "0.08169078826904297  batch_collate\n",
      "0.09187817573547363  batch_collate\n",
      "0.36429929733276367  batch_collate\n",
      "5.5508832931518555 0.4992289968056254\n",
      "0.00016880035400390625 0.4943362497815899\n",
      "0.022732019424438477 0.4897575679334622\n",
      "0.00016379356384277344 0.48504993548760045\n",
      "0.06460261344909668 0.48104567527770997\n",
      "0.00020456314086914062 0.47650943837075865\n",
      "0.04902362823486328 0.47251424388350727\n",
      "0.0001742839813232422 0.4681407257362648\n",
      "0.09843802452087402  batch_collate\n",
      "0.07359480857849121 0.4645210384228908\n",
      "0.00018167495727539062 0.46029977148229423\n",
      "0.08619117736816406 0.45692942378757234\n",
      "0.00020694732666015625 0.45285154453345705\n",
      "0.0904238224029541 0.44964421955885087\n",
      "0.00017023086547851562 0.4457014652720669\n",
      "0.3643977642059326  batch_collate\n",
      "0.2788212299346924 0.44425033279087234\n",
      "0.00017786026000976562 0.44042212182077867\n",
      "0.1049492359161377 0.4375548321976621\n",
      "0.009912967681884766 0.43393074860007075\n",
      "0.056094408035278320.2500886917114258  batch_collate\n",
      "0.2644984722137451  batch_collate\n",
      " 0.43075565330120696\n",
      "0.0002033710479736328 0.42716771761576333\n",
      "0.04414248466491699 0.42400221982278113\n",
      "0.022484540939331055 0.420711091307343\n",
      "0.08222031593322754 0.41795913378397626\n",
      "0.0001842975616455078 0.41458998187895746\n",
      "0.04448246955871582 0.4116291217803955\n",
      "0.0001659393310546875 0.4083635409673055\n",
      "0.0727384090423584 0.40572082339309334\n",
      "0.00017833709716796875 0.4025525227189064\n",
      "0.3157310485839844  batch_collate\n",
      "0.1838359832763672  batch_collate\n",
      "0.14620423316955566  batch_collate\n",
      "0.2485194206237793  batch_collate\n",
      "0.0983119010925293  batch_collate\n",
      "0.3544740676879883  batch_collate\n",
      "0.11151885986328125  batch_collate\n",
      "0.18942856788635254  batch_collate\n",
      "0.22493410110473633  batch_collate\n",
      "0.1026153564453125  batch_collate\n",
      "0.2228848934173584  batch_collate\n",
      "0.08983087539672852  batch_collate\n",
      "0.10960745811462402  batch_collate\n",
      "0.10258841514587402  batch_collate\n",
      "0.36442136764526367  batch_collate\n",
      "0.1708836555480957  batch_collate\n",
      "5.019679069519043 0.4383442013762718\n",
      "0.00728917121887207 0.43502839345198413\n",
      "0.042554616928100586 0.4320324104250842\n",
      "0.00019884109497070312 0.4287609439907652\n",
      "0.39097118377685547  batch_collate\n",
      "0.19417738914489746  batch_collate\n",
      "0.11435508728027344  batch_collate\n",
      "0.14715123176574707  batch_collate\n",
      "0.1767899990081787  batch_collate\n",
      "0.13803362846374512  batch_collate\n",
      "0.11276507377624512  batch_collate\n",
      "0.1284785270690918  batch_collate\n",
      "0.14427423477172852  batch_collate\n",
      "0.25574326515197754  batch_collate\n",
      "0.25965166091918945  batch_collate\n",
      "0.1156153678894043  batch_collate\n",
      "0.09039568901062012  batch_collate\n",
      "0.10199975967407227  batch_collate\n",
      "0.09303593635559082  batch_collate\n",
      "0.12063097953796387  batch_collate\n",
      "0.08722949028015137  batch_collate\n",
      "0.13383102416992188  batch_collate\n",
      "0.12816262245178223  batch_collate\n",
      "0.2235260009765625  batch_collate\n",
      "0.09708046913146973  batch_collate\n",
      "0.29892730712890625  batch_collate\n",
      "0.1240396499633789  batch_collate\n",
      "6.6937196254730225 0.475865896483113\n",
      "0.021462440490722656 0.4724748259160056\n",
      "0.03393697738647461 0.46922639740837946\n",
      "0.00017404556274414062 0.4657774830565733\n",
      "0.023936033248901367 0.4625523629849845\n",
      "0.024649858474731445 0.4593791564305623\n",
      "0.039722442626953125 0.4563600433816155\n",
      "0.0001785755157470703 0.45310160432543073\n",
      "0.029224634170532227 0.4500953846789421\n",
      "0.00018143653869628906 0.4469269765934474\n",
      "0.026030778884887695 0.44398364653954137\n",
      "0.00016999244689941406 0.44090160727500916\n",
      "0.03315901756286621 0.43808958941492543\n",
      "0.013154745101928711 0.4351790767826446\n",
      "0.058365583419799805 0.43261571968493817\n",
      "0.00021505355834960938 0.42969409356246124\n",
      "0.056006669998168945 0.42718612427679487\n",
      "0.00017309188842773438 0.4243393707275391\n",
      "0.027306556701660156 0.4217100143432617\n",
      "0.00018286705017089844 0.4189368094268598\n",
      "0.11107659339904785 0.4169246511521682\n",
      "0.00015091896057128906 0.41421832821585913\n",
      "0.03385281562805176 0.41176435716690557\n",
      "0.00016736984252929688 0.40912591494046724\n",
      "0.02218914031982422 0.40666134949702365\n",
      "0.00017571449279785156 0.40408865560459184\n",
      "0.09163308143615723  batch_collate\n",
      "0.09500908851623535  batch_collate\n",
      "0.08519268035888672 0.40208302054015344\n",
      "0.0002002716064453125 0.39957125335931776\n",
      "0.14548802375793457  batch_collate\n",
      "0.3141450881958008  batch_collate\n",
      "0.21123719215393066  batch_collate\n",
      "0.12010455131530762  batch_collate\n",
      "0.34465909004211426  batch_collate\n",
      "1.7571134567260742 0.4080031925106641\n",
      "0.008534669876098633 0.40553733743267295\n",
      "0.059329986572265625 0.4034133659550017\n",
      "0.00019693374633789062 0.4009547291732416\n",
      "0.30831122398376465  batch_collate\n",
      "0.4292166233062744  batch_collate\n",
      "0.17267060279846191  batch_collate\n",
      "0.0836026668548584  batch_collate\n",
      "0.178511381149292  batch_collate\n",
      "0.14789390563964844  batch_collate\n",
      "0.09724068641662598  batch_collate\n",
      "0.0950157642364502  batch_collate\n",
      "0.20021319389343262  batch_collate\n",
      "0.10095524787902832  batch_collate\n",
      "0.14427423477172852  batch_collate\n",
      "0.25617361068725586  batch_collate\n",
      "0.14158391952514648  batch_collate\n",
      "0.08765983581542969  batch_collate\n",
      "0.07543325424194336  batch_collate\n",
      "0.13648056983947754  batch_collate\n",
      "0.08562469482421875  batch_collate\n",
      "0.14107632637023926  batch_collate\n",
      "0.21900224685668945  batch_collate\n",
      "0.09034323692321777  batch_collate\n",
      "0.14032268524169922  batch_collate\n",
      "0.11375975608825684  batch_collate\n",
      "8.444763422012329 0.4497050848874179\n",
      "0.0002732276916503906 0.4469976640609373\n",
      "0.08742427825927734  batch_collate\n",
      "0.08852362632751465  batch_collate\n",
      "0.07298469543457031  batch_collate\n",
      "0.07826399803161621  batch_collate\n",
      "0.18811345100402832  batch_collate\n",
      "0.1309816837310791  batch_collate\n",
      "0.12629294395446777  batch_collate\n",
      "0.13708209991455078  batch_collate\n",
      "1.9666142463684082 0.45609716455379645\n",
      "0.0010733604431152344 0.4533886895293281\n",
      "0.03116011619567871 0.45089029560427696\n",
      "0.020620346069335938 0.4483592959011302\n",
      "0.08052492141723633 0.44620821768777413\n",
      "0.0002040863037109375 0.4436151704122854\n",
      "0.025882244110107422 0.44120052921978725\n",
      "0.0002129077911376953 0.4386661176023812\n",
      "0.02191305160522461 0.4362846715109689\n",
      "0.00024366378784179688 0.4338071657852693\n",
      "0.27091383934020996  batch_collate\n",
      "0.06724071502685547 0.4317361688883291\n",
      "0.00021910667419433594 0.42931191572982275\n",
      "0.07082438468933105 0.427309192092725\n",
      "0.0002598762512207031 0.42493669589360555\n",
      "0.09321212768554688 0.42310396347256657\n",
      "0.0007164478302001953 0.42078315294705904\n",
      "0.1007542610168457 0.41903436118787757\n",
      "0.029172897338867188 0.41691554888435034\n",
      "0.07828998565673828 0.4150851404344713\n",
      "0.011956453323364258 0.41291778190161593\n",
      "0.11575675010681152 0.41132868547490575\n",
      "0.0004885196685791016 0.409143365444021\n",
      "0.052509307861328125 0.4072564127583983\n",
      "0.001977682113647461 0.40512336680763644\n",
      "0.07138609886169434 0.40337605126865245\n",
      "0.00018596649169921875 0.4012761029104392\n",
      "0.08251953125  batch_collate\n",
      "0.15002727508544922  batch_collate\n",
      "0.7821102142333984 0.40324933664786383\n",
      "0.016644954681396484 0.4012565305552532\n",
      "0.040137290954589844 0.3994046370188395\n",
      "0.00026917457580566406 0.3973682315982118\n",
      "0.22901320457458496  batch_collate\n",
      "0.2692575454711914  batch_collate\n",
      "0.07474231719970703  batch_collate\n",
      "0.08963346481323242  batch_collate\n",
      "0.4207947254180908  batch_collate\n",
      "0.2402803897857666  batch_collate\n",
      "0.2647745609283447  batch_collate\n",
      "0.18195748329162598  batch_collate\n",
      "0.34283900260925293  batch_collate\n",
      "0.4033522605895996  batch_collate\n",
      "0.28220272064208984  batch_collate\n",
      "0.3024759292602539  batch_collate\n",
      "0.22753405570983887  batch_collate\n",
      "0.2587721347808838  batch_collate\n",
      "0.1521146297454834  batch_collate\n",
      "6.5903990268707275 0.42880493614274234\n",
      "0.01499629020690918 0.42671499348650077\n",
      "0.27639245986938477  batch_collate\n",
      "0.1495683193206787  batch_collate\n",
      "0.10166335105895996  batch_collate\n",
      "0.08135628700256348  batch_collate\n",
      "0.289963960647583  batch_collate\n",
      "1.3537728786468506 0.43137357582398994\n",
      "0.0001747608184814453 0.4292175817489624\n",
      "0.05405259132385254 0.4273510892592852\n",
      "0.000179290771484375 0.42523637738558323\n",
      "0.06412482261657715 0.42345750273154875\n",
      "0.0121612548828125 0.42144134465385885\n",
      "0.08171725273132324 0.41978415396155383\n",
      "0.00020074844360351562 0.4177473413134084\n",
      "0.10620546340942383 0.4162423080868191\n",
      "0.00019741058349609375 0.4142420922334378\n",
      "0.03891563415527344 0.41244627185985805\n",
      "0.02993464469909668 0.41062478792099727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17540287971496582  batch_collate\n",
      "0.07106661796569824 0.4090155074946688\n",
      "0.0001773834228515625 0.40708702577734895\n",
      "0.05054283142089844 0.4054131093719196\n",
      "0.019884109497070312 0.40361157198932684\n",
      "0.05747413635253906 0.4020016304282255\n",
      "0.00018715858459472656 0.4001413782437642\n",
      "0.034932613372802734 0.39845838854389803\n",
      "0.015735864639282227 0.3967027806360787\n",
      "0.2533257007598877  batch_collate\n",
      "0.09032225608825684  batch_collate\n",
      "0.09299397468566895  batch_collate\n",
      "0.041975975036621094 0.3950830235328848\n",
      "0.0001938343048095703 0.3932880726727572\n",
      "0.05965137481689453 0.39177840435666733\n",
      "0.0002384185791015625 0.3900147107270387\n",
      "0.19052839279174805 0.38912015324750826\n",
      "0.0002353191375732422 0.38738406023808886\n",
      "0.05970478057861328 0.3859277078840468\n",
      "0.0022521018981933594 0.384230028211543\n",
      "0.05446338653564453 0.38277731172838925\n",
      "0.00019121170043945312 0.3810993025177403\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "Traceback (most recent call last):\n  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/aravind/re/model_lib.py\", line 183, in __getitem__\n    image, masks, class_id = self.load_image_gt(instance_index)\n  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n    instance_info = dataset.instance_info[instance_index]\nIndexError: list index out of range\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f069fcdde189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0ms\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreorder_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcvd_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_next_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatches_outstanding\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_process_next_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_put_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExceptionWrapper\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 307\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: Traceback (most recent call last):\n  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in _worker_loop\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/aravind/anaconda3/envs/myenv/lib/python3.5/site-packages/torch/utils/data/dataloader.py\", line 57, in <listcomp>\n    samples = collate_fn([dataset[i] for i in batch_indices])\n  File \"/home/aravind/re/model_lib.py\", line 183, in __getitem__\n    image, masks, class_id = self.load_image_gt(instance_index)\n  File \"/home/aravind/re/model_lib.py\", line 270, in load_image_gt\n    instance_info = dataset.instance_info[instance_index]\nIndexError: list index out of range\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1862649917602539  batch_collate\n",
      "0.27295446395874023  batch_collate\n",
      "0.11836528778076172  batch_collate\n",
      "0.08787083625793457  batch_collate\n",
      "0.38382959365844727  batch_collate\n",
      "0.10935354232788086  batch_collate\n",
      "0.19980144500732422  batch_collate\n",
      "0.17328786849975586  batch_collate\n",
      "0.4976942539215088  batch_collate\n",
      "0.18766283988952637  batch_collate\n",
      "0.09575080871582031  batch_collate\n",
      "0.10171103477478027  batch_collate\n",
      "0.0992424488067627  batch_collate\n",
      "0.10544538497924805  batch_collate\n",
      "0.13710665702819824  batch_collate\n",
      "0.09762740135192871  batch_collate\n",
      "0.10054922103881836  batch_collate\n",
      "0.13123846054077148  batch_collate\n",
      "0.0937960147857666  batch_collate\n",
      "0.21152949333190918  batch_collate\n",
      "0.20542216300964355  batch_collate\n",
      "0.2550990581512451  batch_collate\n",
      "0.2367231845855713  batch_collate\n",
      "0.3207252025604248  batch_collate\n",
      "0.20450663566589355  batch_collate\n",
      "0.0823066234588623  batch_collate\n",
      "0.25186848640441895  batch_collate\n",
      "0.23706340789794922  batch_collate\n",
      "0.20157647132873535  batch_collate\n",
      "0.09231853485107422  batch_collate\n",
      "0.09194540977478027  batch_collate\n",
      "0.08099985122680664  batch_collate\n",
      "0.07332539558410645  batch_collate\n",
      "0.09052515029907227  batch_collate\n",
      "0.098846435546875  batch_collate\n",
      "0.165208101272583  batch_collate\n",
      "0.17398905754089355  batch_collate\n",
      "0.10049057006835938  batch_collate\n",
      "0.1485128402709961  batch_collate\n",
      "0.12554240226745605  batch_collate\n",
      "0.06628274917602539  batch_collate\n",
      "0.09820890426635742  batch_collate\n",
      "0.0765843391418457  batch_collate\n",
      "0.08033084869384766  batch_collate\n",
      "0.17351841926574707  batch_collate\n",
      "0.10833859443664551  batch_collate\n",
      "0.08075284957885742  batch_collate\n",
      "0.06492233276367188  batch_collate\n",
      "0.05772852897644043  batch_collate\n",
      "0.05588817596435547  batch_collate\n",
      "0.09307289123535156  batch_collate\n",
      "0.06616830825805664  batch_collate\n",
      "0.06124424934387207  batch_collate\n",
      "0.05698728561401367  batch_collate\n",
      "0.05395174026489258  batch_collate\n",
      "0.055127859115600586  batch_collate\n",
      "0.052141427993774414  batch_collate\n"
     ]
    }
   ],
   "source": [
    "z = enumerate(train_loader)\n",
    "import time\n",
    "s = 0\n",
    "N = 1000\n",
    "for i in range(1,N):\n",
    "    start = time.time()\n",
    "    data = next(z)\n",
    "    end = time.time()\n",
    "    s += end-start\n",
    "    print(end-start,s/i)\n",
    "print(s/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "net = model_lib.SimpleHGModel()\n",
    "net.load_state_dict(torch.load(model_dir+\"model_bce_0_7600.pt\"))\n",
    "net = net.cuda()\n",
    "with torch.no_grad():\n",
    "    for i,data in enumerate(val_loader):\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_class_ids = data\n",
    "        a,b,c= batch_images.numpy(), batch_impulses.numpy(),batch_gt_responses.numpy()\n",
    "        a = np.moveaxis(a,1,-1)\n",
    "        b = np.moveaxis(b,1,-1)\n",
    "        c = np.moveaxis(c,1,-1)\n",
    "        Image.fromarray((a[0]*128 + config.MEAN_PIXEL).astype(np.uint8),\"RGB\").show()\n",
    "        Image.fromarray((b[0][:,:,0]*128).astype(np.uint8),\"L\").show()\n",
    "        Image.fromarray((c[0][:,:,0]*128).astype(np.uint8),\"L\").show()\n",
    "        batch_images,batch_impulses,batch_gt_responses,batch_class_ids = batch_images.cuda(),batch_impulses.cuda(),batch_gt_responses.cuda(),batch_class_ids.cuda()\n",
    "        pred_class = net([batch_images,batch_impulses])\n",
    "#         print(pred_class)\n",
    "        pred_class = F.softmax(pred_class,dim=-1).squeeze()\n",
    "        maxs, indices = torch.topk(pred_class,5,-1)\n",
    "        print(maxs.shape,indices.shape)\n",
    "        for i in range(5):\n",
    "            print(maxs[i],indices[i],config.CLASS_NAMES[int(indices[i])])\n",
    "#         print(batch_class_ids)\n",
    "#         print(indices)\n",
    "#         print(\"gt_class:\",config.CLASS_NAMES[int(batch_class_ids[0])])\n",
    "#         print(\"pred_class: \",pred_class[int(batch_class_ids[0])])\n",
    "#         print(config.CLASS_NAMES[int(indices[0])])\n",
    "        input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "np.set_printoptions(threshold=np.nan)\n",
    "counts = [0 for i in range(81)]\n",
    "train_loader = iter(train_loader)\n",
    "for i in range(1000):\n",
    "    start = time.time()\n",
    "    g = next(train_loader)\n",
    "    print(time.time()-start)\n",
    "for i,g in enumerate(train_loader):\n",
    "    print(\"sample:\" + str(i))\n",
    "#     start = time.time()\n",
    "    batch_images,batch_impulses,batch_gt_responses,batch_class_ids = g\n",
    "#     print(batch_class_ids)\n",
    "    for i in batch_class_ids:\n",
    "        counts[int(i.item())] += 1\n",
    "print(counts)\n",
    "#     batch_images = np.moveaxis(batch_images.numpy(),1,-1)\n",
    "#     print(batch_images.shape)\n",
    "#     batch_impulses = batch_impulses.squeeze().numpy()*128\n",
    "#     batch_gt_responses = batch_gt_responses.squeeze().numpy()*128\n",
    "#     batch_class_ids = batch_class_ids.numpy()\n",
    "#     # s =(time.time()-start)\n",
    "#     # print(s)\n",
    "#     batch_images[0] *= 128\n",
    "#     batch_images[0] += config.MEAN_PIXEL\n",
    "#     img = Image.fromarray((batch_images[0]).astype(\"uint8\"),\"RGB\")\n",
    "#     img.show()\n",
    "#     print((np.sum(batch_gt_responses)//128)**0.5)\n",
    "#     mask = Image.fromarray(((batch_gt_responses)).astype(\"uint8\"),\"L\")\n",
    "#     mask.show()\n",
    "#     print(config.CLASS_NAMES[batch_class_ids[0]])\n",
    "#     impulse = Image.fromarray(((batch_impulses)).astype(\"uint8\"),\"L\")\n",
    "#     impulse.show()\n",
    "#     input()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[len(c) for c in train_cid.class_wise_instance_info]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:myenv]",
   "language": "python",
   "name": "conda-env-myenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
